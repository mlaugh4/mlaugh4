<!DOCTYPE html><html lang="en"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Pyrus | Mark Laughery</title><meta name="description" content="Designer and stuff"><meta itemprop="name" content="Mark Laughery"><meta itemprop="description" content="Visualizing diagnostic images (MRI and CT) in VR and MR to improve outcomes and patient education"><meta itemprop="image" content="http://localhost:4000/assets/images/pyrus/pyrus-1.png"><meta property="og:url" content="http://localhost:4000/2017/10/09/pyrus/"><meta property="og:type" content="website"><meta property="og:title" content="Pyrus | Mark Laughery"><meta property="og:site_name" content="Mark Laughery"><meta property="og:description" content="Visualizing diagnostic images (MRI and CT) in VR and MR to improve outcomes and patient education"><meta property="og:image" content="http://localhost:4000/assets/images/pyrus/pyrus-1.png"><meta name="twitter:url" content="http://localhost:4000/2017/10/09/pyrus/"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Pyrus | Mark Laughery"><meta name="twitter:site" content="Mark Laughery"><meta name="twitter:description" content="Visualizing diagnostic images (MRI and CT) in VR and MR to improve outcomes and patient education"><meta name="twitter:creator" content="@mlaugh4"><meta property="twitter:image" content="http://localhost:4000/assets/images/pyrus/pyrus-1.png"><link rel="icon" type="image/x-icon" href="/assets/images/favicon.ico"><link rel="stylesheet" href="/assets/css/app.css"><link rel="alternate" type="application/rss+xml" title="Mark Laughery" href="/feed.xml"><link rel="canonical" href="/2017/10/09/pyrus/"></head><body id="pyrus" class="post-layout"><header class="header"> <a class="header__title" href="http://localhost:4000/">Mark Laughery</a><nav><ul class="header__list"><li><a href="https://www.dropbox.com/s/tpe1a1ykalymwhl/2019-resume.pdf?dl=0">Resume ↗</a></li><li><span>mwlaugh@gmail</span></li></ul></nav></header><main class="mark"><div class="post"><article itemprop="blogPost" itemscope itemtype="http://schema.org/BlogPosting"><div class="post__header section-padding--double"><div class="grid-small"><h2 itemprop="name headline">Pyrus</h2><small>Lead designer and co-founder</small></div></div><div class="post__img"><div><figure class="absolute-bg" style="background-image: url('/assets/images/pyrus/pyrus-1.png');"></figure></div></div><div class="post__content section-padding"><div class="grid"><div id="markdown" itemprop="articleBody"> <iframe src="https://player.vimeo.com/video/367562203" width="640" height="360" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe><p>I spent two years working with doctors in Seattle and Canada to improve MRI/CT imaging. We focused on VR software for perioperative education and AR-based navigation for minimally-invasive procedures.</p><h5>Key contributions</h5><ul><li>Created <mark>business plan</mark> and prototype to secure initial grant</li><li>Developed model management app in React.js</li><li>Built <mark>VR interface</mark> in Unity</li><li>Designed &amp; researched first-of-its-kind VR input model, ‘Touch Motion,’ that combines Oculus Touch and Leap Motion</li><li>Created mobile app that used sockets to connect to a HoloLens and function as a input device</li><li>Led frequent <mark>contextual inquiry and usability analyses</mark> with doctors</li></ul><div class="greyDiv"><div class="grid"><h5>Key design challenges</h5><ul><li>Maintaining a user-centered approach in a highly regulated, complex technical environment with a broad constituency</li><li>Discovery &amp; learning: Building relationships with hospitals and practitioners to establish consistent feedback loop</li><li>Control in VR: Identifying ideal input model that's learnable, precise, and natural</li><li>Tool selection menu: How do users move between different fuctions in VR?</li><li>Model managament: Streamlining the process of importing DICOM images from workstations and getting them into our VR environment</li><li>Pivoting into AR</li></ul></div></div><div class="smll">Challenge 1</div><h2 id="maintaining-a-user-centered-approach-in-a-highly-regulated-complex-technical-environment-with-a-broad-constituency">Maintaining a user-centered approach in a highly regulated, complex technical environment with a broad constituency</h2><h5 id="solution-1-up-front-due-diligence">Solution 1: Up-front due diligence</h5><p><img src="/assets/images/pyrus/product_plan.png" alt="Placeholder" /></p><p>Abstracted product and business planning helped identify tertiary audiences, contextual/regulatory constraints, and aligned all members of the team around key milestones and deliverables. In the face of enigmatic requirements, perpetual famine, and complex healthcare go-to-market, up-front planning helped clarify milestones, recognize wider market trends, and navigate the regulatory labrynth.</p><h5 id="solution-problem-mapping">Solution: Problem mapping</h5><p><img src="/assets/images/pyrus/journey_map.png" alt="Placeholder" /></p><table><thead><tr><th>Challenge</th><th>Outcome</th></tr></thead><tbody><tr><td>Complex service environment</td><td>Clarity and scope of problem</td></tr><tr><td>Diverse constituency</td><td>Understanding of disparate needs and influences</td></tr><tr><td>Many potential use cases</td><td>Artifact for use in interviews</td></tr></tbody></table><div class="greyDiv"><div class="grid"><div class="smll">Challenge 2</div><h2> Discovery &amp; learning: Building relationships with hospitals and practitioners to establish consistent feedback loop</h2><video width="100%" controls="" muted="" autoplay=""> <source src="/assets/images/pyrus/research.mp4" type="video/mp4" /> </video><h5>Solution: Rolling play-pen</h5><p> Anyone who's experimented with VR is familiar with the rats nest of sensors and cables. We spent half the week outside of the office (with a scooter as our primary mode of transportation!) and our caravan was branded the "rolling play-pen." Though we laughed at the time, I now realize it was this tactic that guaranteed our success.</p></div></div><div class="smll">Challenge 3</div><h2 id="control-in-vr-identifying-ideal-input-model-thats-learnable-precise-and-natural">Control in VR: Identifying ideal input model that’s learnable, precise, and natural</h2><p>Our <mark>biggest design challenge</mark> was figuring out how to accomodate ‘natural’ gestures with efficient, precise, and predictable input. Efficiency is critical for doctors and they had a low threshold for onboarding and recall. This was the most important part of our user experience and where we invested the most in research. The following highlights key steps in our investigation.</p><h5 id="experiment-1-google-cardboard">Experiment 1: Google Cardboard</h5><p><img src="/assets/images/pyrus/exp1_googleCardboard.png" alt="Placeholder" /></p><table><thead><tr><th>Benefits</th><th>Drawbacks</th></tr></thead><tbody><tr><td>Mobile; lightweight &amp; accessible</td><td>Way too limited (just gaze and one button)</td></tr><tr><td> </td><td>Laggy with big models</td></tr></tbody></table><h5 id="experiment-2-dk2--leap-motion">Experiment 2: DK2 + Leap Motion</h5><p><img src="/assets/images/pyrus/exp2_dk.png" alt="Placeholder" /></p><table><thead><tr><th>Benefits</th><th>Drawbacks</th></tr></thead><tbody><tr><td>Hardware light (no controller to learn)</td><td>Tracking: Unpredictable &amp; imprecise</td></tr><tr><td>Basic controls are intuitive</td><td>IR silhouette intersection</td></tr></tbody></table><h5 id="experiment-3-xbox-controller">Experiment 3: Xbox controller</h5><p><img src="/assets/images/pyrus/exp3_xbox.jpg" alt="Placeholder" /></p><table><thead><tr><th>Benefits</th><th>Drawbacks</th></tr></thead><tbody><tr><td>Predictable &amp; Comforable</td><td>Difficult to extract substructures</td></tr><tr><td>Lots of input options</td><td>Doctors hated it; felt like gaming.</td></tr></tbody></table><h5 id="experiment-4-perception-neuron">Experiment 4: Perception Neuron</h5><p><img src="/assets/images/pyrus/exp4_neuron.png" alt="Placeholder" /></p><table><thead><tr><th>Benefits</th><th>Drawbacks</th></tr></thead><tbody><tr><td>Performant &amp; Precise tracking</td><td>Way too much configuration</td></tr><tr><td> </td><td>Clunky, fragile hardware</td></tr></tbody></table><h5 id="experiment-5-touch-motion-️">Experiment 5: Touch motion ❤️</h5><video width="100%" controls="" muted="" autoplay=""> <source src="/assets/images/pyrus/exp5_touchmotion.mp4" type="video/mp4" /> </video><div class="greyDiv"><div class="grid"><div class="smll">Challenge 4</div><h2>Action menu with touch motion</h2><p>Touch motion hit the sweet spot between precision and intuition. Our next challenge was to create an efficient system for switching between modes and tools.</p><h5>v1: Pane</h5><img src="/assets/images/pyrus/touchmotion.png" /><p>Users summoned a menu with the controller and selected actions with their free hand. This was easy to create using Unity Canvas and Leap Motion button elements, but it wasn't scalable and prone to selection error.</p><h5>v2: Radial menu</h5><img src="/assets/images/pyrus/design_controller.png" /><table><thead><tr><th>Challenge</th><th>Outcome</th></tr></thead><tbody><tr><td>Hiding functionality behind buttons resulted in recall challenge</td><td>Faster and easily memorized menu selection flow</td></tr><tr><td>Two-handed menus are slow and require dexterity</td><td>Fewer human factors issues</td></tr><tr><td></td><td>MORE new user errors</td></tr></tbody></table></div></div><div class="smll">Challenge 5</div><p>Coming soon!</p></div></div></div></article></div></main><script src="/assets/js/app.min.js"></script></body></html>
  